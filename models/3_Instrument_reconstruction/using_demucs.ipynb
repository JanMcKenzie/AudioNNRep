{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import demucs\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/Shared code/audio/'\n",
    "\n",
    "sys.path.append(\"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/Shared code/AudioNNRep/functions\")\n",
    "import functions as f\n",
    "\n",
    "filenames = f.read_files_in_dir(path)\n",
    "bass = [filename for filename in filenames if \"bass\" in filename]\n",
    "guitar = [filename for filename in filenames if \"guitar\" in filename]\n",
    "vocal = [filename for filename in filenames if \"vocal\" in filename] \n",
    "\n",
    "instruments = [bass, guitar, vocal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/Shared code/AudioNNRep/combo.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bass_electronic_025-048-075.wav', 'guitar_electronic_028-104-100.wav', 'vocal_acoustic_000-059-100.wav']\n",
      "['bass_electronic_027-037-127.wav', 'guitar_electronic_022-084-025.wav', 'vocal_synthetic_003-045-050.wav']\n",
      "['bass_synthetic_009-018-050.wav', 'guitar_electronic_022-064-127.wav', 'vocal_synthetic_003-084-075.wav']\n",
      "['bass_synthetic_033-034-025.wav', 'guitar_acoustic_015-045-100.wav', 'vocal_synthetic_003-033-127.wav']\n",
      "['bass_electronic_018-026-075.wav', 'guitar_acoustic_021-103-075.wav', 'vocal_synthetic_003-091-127.wav']\n",
      "['bass_synthetic_068-074-075.wav', 'guitar_electronic_028-070-127.wav', 'vocal_synthetic_003-062-050.wav']\n",
      "['bass_synthetic_068-052-050.wav', 'guitar_acoustic_021-103-075.wav', 'vocal_acoustic_000-060-050.wav']\n",
      "['bass_electronic_027-026-100.wav', 'guitar_acoustic_010-068-050.wav', 'vocal_synthetic_003-096-075.wav']\n",
      "['bass_synthetic_134-054-050.wav', 'guitar_electronic_028-066-075.wav', 'vocal_synthetic_003-084-075.wav']\n",
      "['bass_electronic_027-031-127.wav', 'guitar_acoustic_021-031-127.wav', 'vocal_synthetic_003-028-025.wav']\n"
     ]
    }
   ],
   "source": [
    "path_combo = \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/\"\n",
    "for j in range(10):\n",
    "    path = \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/audio/nsynth-test.jsonwav/nsynth-test/audio/\"    \n",
    "    pick_bass = np.random.randint(0,len(instruments[0]))\n",
    "    pick_guitar = np.random.randint(0,len(instruments[1]))\n",
    "    pick_vocal = np.random.randint(0,len(instruments[2]))\n",
    "    filenames  = [instruments[0][pick_bass], instruments[1][pick_guitar], instruments[2][pick_vocal]]    \n",
    "    print(filenames)\n",
    "    waveforms = [f.read_wav_file_scipy(path +filenames[0])[0], f.read_wav_file_scipy(path + filenames[1])[0], f.read_wav_file_scipy(path + filenames[2])[0]]                  \n",
    "    combined_wave_form = f.combine_waveforms(waveforms)\n",
    "    f.waveform_to_wavfile(combined_wave_form, path_combo + \"combo\" + str(j) + \".wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
      "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in C:\\Users\\Admin\\OneDrive\\Skrivebord\\Machine Learning\\AppliedML2024-main\\AppliedML2024\\Assignments\\Group Project\\separated\\htdemucs\n",
      "Separating track C:\\Users\\Admin\\OneDrive\\Skrivebord\\Machine Learning\\AppliedML2024-main\\AppliedML2024\\Assignments\\Group Project\\using_demucs_audio\\combo0.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                   | 0.0/5.85 [00:00<?, ?seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5.85/5.85 [00:20<00:00,  3.42s/seconds]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5.85/5.85 [00:20<00:00,  3.42s/seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mImportant: the default model was recently changed to `htdemucs`\u001b[0m the latest Hybrid Transformer Demucs model. In some cases, this model can actually perform worse than previous models. To get back the old default model use `-n mdx_extra_q`.\n",
      "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in C:\\Users\\Admin\\OneDrive\\Skrivebord\\Machine Learning\\AppliedML2024-main\\AppliedML2024\\Assignments\\Group Project\\separated\\htdemucs\n",
      "Separating track C:\\Users\\Admin\\OneDrive\\Skrivebord\\Machine Learning\\AppliedML2024-main\\AppliedML2024\\Assignments\\Group Project\\using_demucs_audio\\combo1.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                   | 0.0/5.85 [00:00<?, ?seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5.85/5.85 [00:18<00:00,  3.18s/seconds]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 5.85/5.85 [00:18<00:00,  3.18s/seconds]\n"
     ]
    }
   ],
   "source": [
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo0.wav\" \n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo1.wav\"\n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo2.wav\"\n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo3.wav\"\n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo4.wav\"\n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo5.wav\"\n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo6.wav\"\n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo7.wav\"\n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo8.wav\"\n",
    "!python -m demucs.separate \"C:/Users/Admin/OneDrive/Skrivebord/Machine Learning/AppliedML2024-main/AppliedML2024/Assignments/Group Project/using_demucs_audio/combo9.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
